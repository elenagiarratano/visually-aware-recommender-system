{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVBPR Model – Deep Visually-Aware Bayesian Personalized Ranking\n",
    "\n",
    "The .py script ___original-source-code/DVBPR/main.py___ reports both the training of the DVBPR and definition of the model itself. When translating it to get Keras-based code, we separate the model definition from the training pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> DVBPR jointly learn user latent factors and extract task-guided visual features from implicit feedback for fashion recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modules we have to develop follow.\n",
    "* ___Convolutional Neural Network (CNN)___ \n",
    "    > Our last layer has K dimensions. Here, instead of seeking a final layer that can be adapted to general-purpose prediction tasks, we hope to learn a representation whose dimensions explain the variance in users’ fashion preferences.\n",
    "\n",
    "* [___Convolutional Siamese Network___](https://sorenbouma.github.io/blog/oneshot/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run-through: How to build models in Keras\n",
    "\n",
    "There are two ways to build Keras models: __sequential__ and __functional__.\n",
    "\n",
    "* The sequential API allows you to create models __layer-by-layer__ for most problems. It is limited in that it ___does not___ allow you to create models that share layers or have multiple inputs or outputs.\n",
    "\n",
    "* Alternatively, the functional API allows you to create models that have a lot ___more flexibility___ as you can easily define models where __layers connect to more than just the previous and next layers__. In fact, you can connect layers to (literally) any other layer. As a result, creating complex networks such as siamese networks become possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese leg – Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  Run-through: CNN Layers\n",
    "\n",
    "* __Batch Normalization__ is used to normalize the activations of a given input volume before passing it to the next layer in the network. It has been proven to be very effective at reducing the number of epochs required to train a CNN as well as stabilizing training itself.\n",
    "* __POOL__ layers have a primary function of progressively reducing the spatial size (i.e. width and height) of the input volume to a layer. It is common to insert POOL layers between consecutive CONV layers in a CNN architecture.\n",
    "* __Dropout__ is an interesting concept not to be overlooked. In an effort to force the network to be more robust we can apply dropout, the process of disconnecting random neurons between layers. This process is proven to reduce overfitting, increase accuracy, and allow our network to generalize better for unfamiliar images.\n",
    "\n",
    "Via the __Sequential model API__, ___layers are added piecewise via the Sequential object___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(width,\n",
    "        height,\n",
    "        depth,\n",
    "        latent_dim,\n",
    "        w_init=\"RandomNormal\",\n",
    "        cnn_w_regularizer=None,\n",
    "        fc_w_regularizer=None,\n",
    "        b_init=\"RandomNormal\"):\n",
    "        \"\"\"\n",
    "        Build the CNN.\n",
    "\n",
    "            :param width (int): Image width in pixels.\n",
    "            :param height (int): The image height in pixels.\n",
    "            :param depth (int): The number of channels for the image.\n",
    "            :param latent_dim (int): Dimesion of the latent space - embedding of the image.\n",
    "            :param w_init=\"he_normal\" (str): The kernel initializer.\n",
    "            :param cnn_w_regularizer=None (str): Regularization method.\n",
    "            :param fc_w_regularizer=None (str): Regularization method.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential(name='cnn')\n",
    "        input_shape = (height, width, depth)\n",
    "        chan_dim = -1\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            input_shape = (depth, height, width)\n",
    "            chan_dim = 1\n",
    "\n",
    "        # conv1\n",
    "        #\n",
    "        # Our first CONV layer will learn a total of 64 filters, each\n",
    "        # of which are 11x11 -- we'll then apply 4x4 strides to reduce\n",
    "        # the spatial dimensions of the volume\n",
    "        # Moreover, a max-pooling layer is added\n",
    "        model.add(Conv2D(64, (11, 11),\n",
    "                         strides=(4, 4),\n",
    "                         padding=\"valid\",\n",
    "                         kernel_initializer=w_init,\n",
    "                         kernel_regularizer=cnn_w_regularizer,\n",
    "                         bias_initializer=b_init,\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                               padding=\"same\"))\n",
    "\n",
    "        # conv2\n",
    "        #\n",
    "        # Here we stack one more CONV layer on top,\n",
    "        # each layer will learn a total of 256 (5x5) filters\n",
    "        # A max-pooling layer is added\n",
    "        model.add(ZeroPadding2D(padding=(2, 2)))\n",
    "        model.add(Conv2D(256, (5, 5),\n",
    "                         strides=(1, 1),\n",
    "                         kernel_initializer=w_init,\n",
    "                         kernel_regularizer=cnn_w_regularizer,\n",
    "                         bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                               padding=\"same\"))\n",
    "\n",
    "        # conv3\n",
    "        #\n",
    "        # Stack one more CONV layer, keeping 256 total learned filters\n",
    "        # but decreasing the the size of each filter to 3x3\n",
    "        model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "        model.add(Conv2D(256, (3, 3),\n",
    "                         strides=(1, 1),\n",
    "                         kernel_initializer=w_init,\n",
    "                         kernel_regularizer=cnn_w_regularizer,\n",
    "                         bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        # Two more CONV layers, same filter size and number\n",
    "        #\n",
    "        # conv4\n",
    "        model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "        model.add(Conv2D(256, (3, 3),\n",
    "                         strides=(1, 1),\n",
    "                         kernel_initializer=w_init,\n",
    "                         kernel_regularizer=cnn_w_regularizer,\n",
    "                         bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        # conv5\n",
    "        model.add(ZeroPadding2D(padding=(1, 1)))\n",
    "        model.add(Conv2D(256, (3, 3),\n",
    "                         strides=(1, 1),\n",
    "                         kernel_initializer=w_init,\n",
    "                         kernel_regularizer=cnn_w_regularizer,\n",
    "                         bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                               padding=\"same\"))\n",
    "\n",
    "        # Two fully-connected layers on top of each other\n",
    "        #\n",
    "        # full1\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4096,\n",
    "                        kernel_initializer=w_init,\n",
    "                        kernel_regularizer=fc_w_regularizer,\n",
    "                        bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # full2\n",
    "        model.add(Dense(4096,\n",
    "                        kernel_initializer=w_init,\n",
    "                        kernel_regularizer=fc_w_regularizer,\n",
    "                        bias_initializer=b_init))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # full3\n",
    "        model.add(Dense(latent_dim,\n",
    "                        kernel_initializer=w_init,\n",
    "                        kernel_regularizer=fc_w_regularizer,\n",
    "                        bias_initializer=b_init))\n",
    "\n",
    "        # Any classifier layer (e.g. see softmax below) is added\n",
    "        # since getting an embedding model is the goal here but solving a prediction task\n",
    "        # model.add(Dense(classes))\n",
    "        # model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # Return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_net = CNN(width=224,\n",
    "               height=224,\n",
    "               depth=3,\n",
    "               latent_dim=100,\n",
    "               cnn_w_regularizer=l2(1e-3),\n",
    "               fc_w_regularizer=l2(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIAMESE LEG - CNN\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 64)        23296     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 256)       409856    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              51384320  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               409700    \n",
      "=================================================================\n",
      "Total params: 70,778,724\n",
      "Trainable params: 70,778,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSIAMESE LEG - CNN\")\n",
    "conv_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvSiameseNet\n",
    "\n",
    "Since we want the same parameters used for both inputs,\n",
    "    1. We define the twin network’s architecture once as a Sequential() model\n",
    "    2. Call it with respect to each of two input layers \n",
    "\n",
    "Therefore, \n",
    "    3. The two input layers are merged together through absolute distance\n",
    "    4. An output layer is added\n",
    "\n",
    "In this case, the __Keras functional API__ needs to be used: it provides a more flexible way for defining models.\n",
    "\n",
    "> Specifically, it allows you to define multiple input or output models as well as models that __share layers__. More than that, it allows you to define ad hoc acyclic network graphs.\n",
    "\n",
    "> ___Models are defined by creating instances of layers and connecting them directly to each other in pairs, and then defining a Model that specifies the layers to act as the input and output to the model, via the parameters inputs and outputs, respectively.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Concatenate, Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvSiameseNet(users_dim,\n",
    "                   width,\n",
    "                   height,\n",
    "                   depth,\n",
    "                   latent_dim,\n",
    "                   w_init=\"RandomNormal\",\n",
    "                   cnn_w_regularizer=None,\n",
    "                   fc_w_regularizer=None,\n",
    "                   u_w_regularizer=None,\n",
    "                   b_init=\"RandomNormal\"):\n",
    "\n",
    "        # Define the input\n",
    "        #   Unlike the Sequential model, you must create and define\n",
    "        #   a standalone \"Input\" layer that specifies the shape of input\n",
    "        #   data. The input layer takes a \"shape\" argument, which is a\n",
    "        #   tuple that indicates the dimensionality of the input data.\n",
    "        user_input = Input((1,))\n",
    "        user_E = Input((users_dim * latent_dim, latent_dim),\n",
    "                       name=\"user_matrix\")\n",
    "\n",
    "        image_shape = (width, height, depth)\n",
    "        left_input = Input(image_shape,\n",
    "                           name=\"observed_image\")\n",
    "        right_input = Input(image_shape,\n",
    "                            name=\"non_observed_image\")\n",
    "\n",
    "        # Build convnet to use in each siamese 'leg'\n",
    "        conv_net = CNN(width,\n",
    "                       height,\n",
    "                       depth,\n",
    "                       latent_dim,\n",
    "                       w_init,\n",
    "                       cnn_w_regularizer,\n",
    "                       fc_w_regularizer,\n",
    "                       b_init)\n",
    "\n",
    "        # Connecting layers\n",
    "        #   The layers in the model are connected pairwise.\n",
    "        #   This is done by specifying where the input comes from when\n",
    "        #   defining each new layer. A bracket notation is used, such that\n",
    "        #   after the layer is created, the layer from which the input to\n",
    "        #   the current layer comes from is specified.\n",
    "        #\n",
    "        # merge the two encoded inputs through the L1 distance\n",
    "        L1_distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]),\n",
    "                             name=\"score_difference\")\n",
    "\n",
    "        # user's preferences theta_u\n",
    "        theta_user = []\n",
    "        for u in range(users_dim):\n",
    "            theta_user.append(Dense(latent_dim,\n",
    "                                    kernel_initializer=w_init,\n",
    "                                    kernel_regularizer=u_w_regularizer,\n",
    "                                    bias_initializer=b_init,\n",
    "                                    name=\"user_%.0f_preferences\" % (u)))\n",
    "\n",
    "        # concatenate all users' preferences vectors to get the\n",
    "        # users' preferences matrix Theta\n",
    "        concatenate = Concatenate(axis=-1,\n",
    "                                  name=\"theta\")\n",
    "\n",
    "        # single user's preferences theta_u\n",
    "        user_preference = Dot(axes=1,\n",
    "                              name=\"theta_u\")\n",
    "\n",
    "        # preference layer\n",
    "        preference_relationship = Dot(axes=1,\n",
    "                                      name=\"score_rank\")\n",
    "\n",
    "        # Apply the pipeline to the inputs\n",
    "        #\n",
    "        # call the convnet Sequential model on each of the input tensors\n",
    "        # so params will be shared\n",
    "        encoded_l = conv_net(left_input)\n",
    "        encoded_r = conv_net(right_input)\n",
    "\n",
    "        # merge the two encoded inputs through the L1 distance\n",
    "        L1_dist = L1_distance([encoded_l, encoded_r])\n",
    "\n",
    "        # concatenate user's preferences theta_u to get the preferences\n",
    "        # matrix Theta\n",
    "        theta_urs = []\n",
    "        for u in range(users_dim):\n",
    "            theta_urs.append(theta_user[u](user_input))\n",
    "        theta = concatenate(theta_urs)\n",
    "\n",
    "        # retrieve the single user preference\n",
    "        theta_ur = user_preference([user_E, theta])\n",
    "\n",
    "        # get the preference score\n",
    "        prediction = preference_relationship([theta_ur, L1_dist])\n",
    "\n",
    "        # Create the model\n",
    "        #   After creating all of your model layers and connecting them\n",
    "        #   together, you must then define the model.\n",
    "        #   As with the Sequential API, the model is the thing that you can\n",
    "        #   summarize, fit, evaluate, and use to make predictions.\n",
    "        #   Keras provides a \"Model\" class that you can use to create a model\n",
    "        #   from your created layers. It requires that you only specify the\n",
    "        #   input and output layers.\n",
    "        model = Model(inputs=[user_input, user_E, left_input, right_input],\n",
    "                      outputs=prediction)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_conv_net = ConvSiameseNet(users_dim=5,\n",
    "                                  width=224,\n",
    "                                  height=224,\n",
    "                                  depth=3,\n",
    "                                  latent_dim=100,\n",
    "                                  cnn_w_regularizer=l2(1e-3),\n",
    "                                  fc_w_regularizer=l2(1e-3),\n",
    "                                  u_w_regularizer=l2(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CONVOLUTIONAL SIAMESE NET - example with users_dim=5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_0_preferences (Dense)      (None, 100)          200         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_1_preferences (Dense)      (None, 100)          200         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_2_preferences (Dense)      (None, 100)          200         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_3_preferences (Dense)      (None, 100)          200         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_4_preferences (Dense)      (None, 100)          200         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "observed_image (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "non_observed_image (InputLayer) (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_matrix (InputLayer)        (None, 500, 100)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "theta (Concatenate)             (None, 500)          0           user_0_preferences[0][0]         \n",
      "                                                                 user_1_preferences[0][0]         \n",
      "                                                                 user_2_preferences[0][0]         \n",
      "                                                                 user_3_preferences[0][0]         \n",
      "                                                                 user_4_preferences[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cnn (Sequential)                (None, 100)          70778724    observed_image[0][0]             \n",
      "                                                                 non_observed_image[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "theta_u (Dot)                   (None, 100)          0           user_matrix[0][0]                \n",
      "                                                                 theta[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "score_difference (Lambda)       (None, 100)          0           cnn[1][0]                        \n",
      "                                                                 cnn[2][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "score_rank (Dot)                (None, 1)            0           theta_u[0][0]                    \n",
      "                                                                 score_difference[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 70,779,724\n",
      "Trainable params: 70,779,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCONVOLUTIONAL SIAMESE NET - example with users_dim=5\")\n",
    "siamese_conv_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DVBPR(users_dim,\n",
    "          width,\n",
    "          height,\n",
    "          depth,\n",
    "          latent_dim,\n",
    "          w_init=\"RandomNormal\",\n",
    "          cnn_w_regularizer=None,\n",
    "          fc_w_regularizer=None,\n",
    "          u_w_regularizer=None,\n",
    "          b_init=\"RandomNormal\"):\n",
    "\n",
    "        # Define the input\n",
    "        #   Unlike the Sequential model, you must create and define\n",
    "        #   a standalone \"Input\" layer that specifies the shape of input\n",
    "        #   data. The input layer takes a \"shape\" argument, which is a\n",
    "        #   tuple that indicates the dimensionality of the input data.\n",
    "        user_input = Input((1,))\n",
    "        user_E = Input((users_dim * latent_dim, latent_dim),\n",
    "                       name=\"user_matrix\")\n",
    "\n",
    "        image_shape = (width, height, depth)\n",
    "        image_input = Input(image_shape,\n",
    "                            name=\"observed_image\")\n",
    "\n",
    "        # Build convnet to use in each siamese 'leg'\n",
    "        conv_net = CNN(width,\n",
    "                       height,\n",
    "                       depth,\n",
    "                       latent_dim,\n",
    "                       w_init,\n",
    "                       cnn_w_regularizer,\n",
    "                       fc_w_regularizer,\n",
    "                       b_init)\n",
    "\n",
    "        # Connecting layers\n",
    "        #   The layers in the model are connected pairwise.\n",
    "        #   This is done by specifying where the input comes from when\n",
    "        #   defining each new layer. A bracket notation is used, such that\n",
    "        #   after the layer is created, the layer from which the input to\n",
    "        #   the current layer comes from is specified.\n",
    "        #\n",
    "        # user's preferences theta_u\n",
    "        theta_user = []\n",
    "        for u in range(users_dim):\n",
    "            theta_user.append(Dense(latent_dim,\n",
    "                                    kernel_initializer=w_init,\n",
    "                                    kernel_regularizer=u_w_regularizer,\n",
    "                                    bias_initializer=b_init,\n",
    "                                    name=\"user_%.0f_preferences\" % (u)))\n",
    "\n",
    "        # concatenate all users' preferences vectors to get the\n",
    "        # users' preferences matrix Theta\n",
    "        concatenate = Concatenate(axis=-1,\n",
    "                                  name=\"theta\")\n",
    "\n",
    "        # single user's preferences theta_u\n",
    "        user_preference = Dot(axes=1,\n",
    "                              name=\"theta_u\")\n",
    "\n",
    "        # preference layer\n",
    "        preference_relationship = Dot(axes=1,\n",
    "                                      name=\"score_rank\")\n",
    "\n",
    "        # Apply the pipeline to the inputs\n",
    "        #\n",
    "        # call the convnet Sequential model on each of the input tensors\n",
    "        # so params will be shared\n",
    "        encoded_i = conv_net(image_input)\n",
    "\n",
    "        # concatenate user's preferences theta_u to get the preferences\n",
    "        # matrix Theta\n",
    "        theta_urs = []\n",
    "        for u in range(users_dim):\n",
    "            theta_urs.append(theta_user[u](user_input))\n",
    "        theta = concatenate(theta_urs)\n",
    "\n",
    "        # retrieve the single user preference\n",
    "        theta_ur = user_preference([user_E, theta])\n",
    "\n",
    "        # get the preference score\n",
    "        prediction = preference_relationship([theta_ur, encoded_i])\n",
    "\n",
    "        # Create the model\n",
    "        #   After creating all of your model layers and connecting them\n",
    "        #   together, you must then define the model.\n",
    "        #   As with the Sequential API, the model is the thing that you can\n",
    "        #   summarize, fit, evaluate, and use to make predictions.\n",
    "        #   Keras provides a \"Model\" class that you can use to create a model\n",
    "        #   from your created layers. It requires that you only specify the\n",
    "        #   input and output layers.\n",
    "        model = Model(inputs=[user_input, user_E, image_input],\n",
    "                      outputs=prediction)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvbpr = DVBPR(users_dim=5,\n",
    "              width=224,\n",
    "              height=224,\n",
    "              depth=3,\n",
    "              latent_dim=100,\n",
    "              cnn_w_regularizer=l2(1e-3),\n",
    "              fc_w_regularizer=l2(1e-3),\n",
    "              u_w_regularizer=l2(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEEP VISUAL BAYESIAN PERSONALIZED RANKING - example with users_dim=5\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_0_preferences (Dense)      (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_1_preferences (Dense)      (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_2_preferences (Dense)      (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_3_preferences (Dense)      (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_4_preferences (Dense)      (None, 100)          200         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_matrix (InputLayer)        (None, 500, 100)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "theta (Concatenate)             (None, 500)          0           user_0_preferences[0][0]         \n",
      "                                                                 user_1_preferences[0][0]         \n",
      "                                                                 user_2_preferences[0][0]         \n",
      "                                                                 user_3_preferences[0][0]         \n",
      "                                                                 user_4_preferences[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "observed_image (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "theta_u (Dot)                   (None, 100)          0           user_matrix[0][0]                \n",
      "                                                                 theta[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cnn (Sequential)                (None, 100)          70778724    observed_image[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "score_rank (Dot)                (None, 1)            0           theta_u[0][0]                    \n",
      "                                                                 cnn[1][0]                        \n",
      "==================================================================================================\n",
      "Total params: 70,779,724\n",
      "Trainable params: 70,779,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDEEP VISUAL BAYESIAN PERSONALIZED RANKING - example with users_dim=5\")\n",
    "dvbpr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13875212510363869932\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
