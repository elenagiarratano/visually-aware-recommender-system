{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Env settings\n",
    "\n",
    "Get ready! Find all the details to set up your machine in the *set-up/set_up.ipynb* Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your local path to the labcamp directory \n",
    "# ...\n",
    "path = \\\n",
    " {\n",
    "     \"log\": os.path.join(home, \"log\"),\n",
    "     \"udf\": os.path.join(home, \"src\"),\n",
    "     \"data\": os.path.join(home, \"data\"),\n",
    "     \"model\": os.path.join(home, \"models\")\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, path[\"udf\"])\n",
    "\n",
    "import ipynb.fs.full.utils as utils\n",
    "\n",
    "def log_info(logger, \n",
    "             info_string,\n",
    "             end=None,\n",
    "             video_print=True):\n",
    "    logger.info(info_string)\n",
    "    if video_print:\n",
    "        print(info_string, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the file where we'll save the progress during the model training\n",
    "logger, logfile_name = utils.LogFile(directory=path[\"log\"]).get_logfile()\n",
    "log_info(logger, \"NEXT OUTFIT LABCAMP - Model training\\n\", video_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _AmazonFashion_ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "clock_start = datetime.now()\n",
    "dataset = np.load(os.path.join(path[\"data\"], \"AmazonFashion6ImgPartitioned.npy\"), \n",
    "                  encoding=\"bytes\")\n",
    "[user_train, user_validation, user_test, items, user_num, item_num] = dataset\n",
    "\n",
    "process_duration = datetime.now() - clock_start\n",
    "log_info(logger, \"Loading data took %.2f seconds\" % (process_duration.seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It consists of reviews of clothing items crawled from _Amazon.com_\n",
    "* It contains six representative fashion categories (men/women’s tops, bottoms and shoes)\n",
    "* We treat users’ reviews as ***implicit feedback***:\n",
    "    > If an item $i$ has been reviewed, then $i$ is referred to as *observed* and will have preference score higher than the preference score assigned to a *not-observed* item $j$\n",
    "* __For data preprocessing, inactive users _u_ (for whom $|I_u^+| < 5$) have been discarded. __\n",
    "* __For each user, one action for validation and another for testing have been witheld randomly. All remaining items are used for training.__\n",
    "\n",
    "Amazon datasets are derived from [here](http://jmcauley.ucsd.edu/data/amazon/). Please cite the corresponding papers if you use the datasets. __Please note that raw images are for academic use only.__\n",
    "\n",
    "##### Take time to take a look at the data structure. What you'll find out:\n",
    "<img style=\"float:right;margin:0px 30px 10px 50px\" width=\"50%\" src=\"imgs/cover.jpg\"/> \n",
    "\n",
    "> * ***user_num*** is the total number of users\n",
    "* ***item_num*** is the total number of reviewed items\n",
    "* ***user_train***, ***user_validation***, ***user_test*** store users' review info:\n",
    "    - The user is identified by ***reviewerID*** and ***reviewerName***\n",
    "    - ***user_train***, ***user_validation***, ***user_test*** are dictionaries, the key is a mapping into $[0:$ ***user_num***$]$ of the ***reviewerID*** field\n",
    "    - Each element of ***user_**** is a list of some of the reviews made by the considered user: the complete set of reviews made by that user has been split in order to create training (N items), test (1 item), and validation (1 item) sets.\n",
    "    - Each element of the list is a new dict storing the actual info, see the example below\n",
    "* ***items*** is a dict and each element stores info about one specific item, identified by __asin__\n",
    "    - The dict key is a mapping into $[0:$ ***item_num***$]$ of the ***asin*** field\n",
    "    - If exists, the ***related*** filed is very interesting: it's a dict having keys ***also_bought*** and ***also_viewed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB Your proxy settings may cause some problems\n",
    "for item_idx in random.sample(range(len(items)), k=20):\n",
    "    title = items[item_idx][b'title'].decode(\"utf-8\")\n",
    "    categories = items[item_idx][b'categories']\n",
    "    cat = \"; \".join(np.unique([c.decode(\"utf-8\") for c in sum(categories, [])]))\n",
    "    \n",
    "    img = utils.image_displayer(items[item_idx][b'imUrl'].decode(\"utf-8\"))\n",
    "    print(\"Title: %s\" % (title))\n",
    "    print(\"Categories: %s\" % (cat))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"user_num: %.0f\" % (user_num))\n",
    "print(\"len of user_train: %.0f\" % (len(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"item_num: %.0f\" % (item_num))\n",
    "print(\"len of items: %.0f\" % (len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = []\n",
    "for u in user_train.keys():\n",
    "    iii += [item[b'productid'] for item in user_train[u]]\n",
    "ii_train = np.unique(iii)\n",
    "len(ii_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iii = []\n",
    "for u in user_test.keys():\n",
    "    iii += [item[b'productid'] for item in user_test[u]]\n",
    "ii_test = np.unique(iii)\n",
    "len(ii_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ii_test).intersection(ii_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train[random.randrange(user_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = random.randrange(item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[idx].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Visually-aware Fashion Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An end-to-end approach\n",
    "\n",
    "We'll develop an **end-to-end visually-aware ranking method** to *simultaneously extract task-guided visual features and learn user latent factors*.\n",
    "\n",
    "<img style=\"float:left;margin:10px 30px 0px 30px\" width=\"52%\" src=\"imgs/clothes2bit.png\"/> \n",
    "\n",
    "Our goal is to generate, for each user $u$, a **personalized ranking over items the user $u$ has not interacted with yet**.\n",
    "\n",
    "To achieve this, \n",
    "* We set the preference predictor of a user $u$ about an item $i$ as the score given by $$x_{u,i} = \\theta_u^T \\Phi(X_i)$$, where $\\theta_u$ is the user latent factors; $\\Phi(X_i)$ is the embedding of the item image. \n",
    "$$x_{u,i} \\in \\mathbb{R}^K$$, where $\\mathbb{R}^K$ is the **K-dimensional latent space** whose dimensions correspond to facets of fashion style that explain **variance in users’ opinions**.\n",
    "\n",
    "\n",
    "* We choose the **Bayesian Personalized Ranking (BPR)** as learning method, namely the state-of-the-art ranking optimization framework for implicit feedback. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:right;margin:25px 30px 0px 43px\" width=\"37%\" src=\"imgs/doilikeit.png\"/> \n",
    "\n",
    "### Training on batches via bootstrap sampling of triples\n",
    "\n",
    "In BPR, the main idea is\n",
    "* to optimize rankings by considering **randomly-selected triplets** $$(user, observed-item, not-observed-item)$$\n",
    "* to seek to maximize an **objective function** given by $$\\sum \\ln(\\sigma(x_{uij}))$$, i.e. the number of times in which $$x_{u, observed-i} \\geq x_{u, not-observed-i} $$\n",
    "\n",
    "Each training iteration (__epoch__) involves $B$ batches of data. For each sample batch, we compute the training and the validation sets.\n",
    "* __Training set.__ Composed of $N = B \\times$__batch_size__ users: for each user, one pair _(observed item, not-observed item)_ is randomly chosen.\n",
    "* __Validation set.__ Composed of all the users that have been selected in the training set: for each user, $M$ pairs _($v$, not-observed item)_ are randomly chosen, with $v$ the single observed item stored in ***user_validation*** for the considered user.\n",
    "\n",
    "\n",
    "### Performance validation via AUC\n",
    "\n",
    "* The AUC measures the quality of a ranking based on pairwise comparisons\n",
    "* The AUC is the measure that BPR-like methods are trained to optimize\n",
    "\n",
    "Basically, we are **counting the fraction of times that the \"observed\" items $i$ are preferred over \"non-observed\" items $j$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_train_validation_sample_batch(user_train_ratings,\n",
    "                                          user_validation_ratings,\n",
    "                                          item_images,\n",
    "                                          batch_size,\n",
    "                                          image_width=224,\n",
    "                                          image_height=224,\n",
    "                                          validation_sample_count=1000):\n",
    "    \"\"\"\n",
    "    validation_sample_count (int): Number of not-observed items to sample to get the validation set for each user.\n",
    "    \"\"\"\n",
    "\n",
    "    triplet_train_batch = {}\n",
    "    triplet_validation_batch = {}\n",
    "    for b in range(batch_size):\n",
    "        # user id\n",
    "        u = random.randrange(len(user_train_ratings))\n",
    "\n",
    "        # training set\n",
    "        i = ...                                          # >> COMPLETE HERE!\n",
    "        j = ...                                          # >> COMPLETE HERE!\n",
    "        \n",
    "        image_i = image_translate(item_images[i][b'imgs'], \n",
    "                                  image_width, \n",
    "                                  image_height)\n",
    "        image_j = image_translate(item_images[j][b'imgs'],\n",
    "                                  image_width, \n",
    "                                  image_height)\n",
    "        triplet_train_batch[u] = [image_i,\n",
    "                                  image_j]\n",
    "\n",
    "        # validation set\n",
    "        i = ...                                          # >> COMPLETE HERE!\n",
    "        image_i = image_translate(item_images[i][b'imgs'],\n",
    "                                  image_width, \n",
    "                                  image_height)\n",
    "\n",
    "        reviewed_items = set()\n",
    "        for item in user_train_ratings[u]:\n",
    "            reviewed_items.add(item[b'productid'])\n",
    "        reviewed_items.add(user_validation_ratings[u][0][b'productid'])\n",
    "\n",
    "        triplet_validation_batch[u] = []\n",
    "        for j ...                                        # >> COMPLETE HERE!\n",
    "            if j ...                                     # >> COMPLETE HERE!\n",
    "                image_j = image_translate(item_images[j][b'imgs'],\n",
    "                                          image_width, \n",
    "                                          image_height)\n",
    "                triplet_validation_batch[u].append([image_i,\n",
    "                                                    image_j])\n",
    "        \n",
    "    return triplet_train_batch, triplet_validation_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss function as ln(sigmoid) according to the BPR method\n",
    "# Pay attention.\n",
    "# BPR wants to maximize the loss function while Keras engine minimizes it\n",
    "def softplus_loss(label_matrix, prediction_matrix):\n",
    "    return K.mean(K.softplus(-prediction_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the metric as AUC according to the BPR method\n",
    "#\n",
    "# Count the ratio of prediction value > 0\n",
    "# i.e., predicting positive item score > negative item score for a user\n",
    "#\n",
    "# Pay attention.\n",
    "# Do not use a plain integer as a parameter to keras.backend.switch,\n",
    "# instead, pass a compatible tensor (for example create it with keras.backend.zeros_like)\n",
    "def auc(label_tensor, prediction_tensor):\n",
    "    return K.mean(...)                                   # >> COMPLETE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Let's move to the *src/convolutional_siameseNet.ipynb* Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import model_from_yaml\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import ipynb.fs.full.convolutional_siameseNet as model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network params\n",
    "# image size\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# latent dimensionality K\n",
    "latent_dimensionality = 100\n",
    "\n",
    "# weight decay - conv layer\n",
    "lambda_cnn = 1e-3  # 2e-4\n",
    "# weight decay - fc layer\n",
    "lambda_fc = 1e-3\n",
    "# regularizer for theta_u\n",
    "lambda_u = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training params\n",
    "# epoch params\n",
    "learning_rate = 1e-4\n",
    "training_epoch = 3 # 30\n",
    "batch_count = 2**8\n",
    "# batch_size = 2**7\n",
    "validation_sample_count = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's consider a subset of users to speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_info(logger, \"original total nb of users: %.0f\" % user_num)\n",
    "user_num_original = user_num\n",
    "user_train_original = user_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each batch, force the number of users to be the same\n",
    "batch_count = 2**8\n",
    "user_num = (user_num_original - (user_num_original % batch_count))\n",
    "log_info(logger, \"total nb of users: %.0f\" % user_num)\n",
    "\n",
    "# one complete model will be linked to each user_subset\n",
    "user_subsets = dict(zip(range(batch_count), np.array_split(range(user_num), batch_count)))\n",
    "log_info(logger, \"total nb of batches: %.0f\" % len(user_subsets))\n",
    "log_info(logger, \"users per batch: %.0f\" % len(user_subsets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider 2**4 batches of users\n",
    "batch_count = 2**4\n",
    "user_num = len(user_subsets[0]) * batch_count\n",
    "log_info(logger, \"nb of considered users: %.0f\" % user_num)\n",
    "user_subsets = dict(zip(range(batch_count), np.array_split(range(user_num), batch_count)))\n",
    "log_info(logger, \"nb of considered batches: %.0f\" % len(user_subsets))\n",
    "log_info(logger, \"users per batch: %.0f\" % len(user_subsets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set and compile the DVBPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clock_start = datetime.now()\n",
    "conv_siamese_net = model.ConvSiameseNet(users_dim=len(user_subsets[0]),\n",
    "                                        width=image_width,\n",
    "                                        height=image_height,\n",
    "                                        depth=3,\n",
    "                                        latent_dim=latent_dimensionality,\n",
    "                                        cnn_w_regularizer=l2(lambda_cnn),\n",
    "                                        fc_w_regularizer=l2(lambda_fc),\n",
    "                                        u_w_regularizer=l2(lambda_u)\n",
    "                                        )\n",
    "process_duration = datetime.now() - clock_start\n",
    "log_info(logger, \n",
    "         \"Building Convolutional SiameseNet model (%.0f params) took %.2f minutes\" % (conv_siamese_net.count_params(), \n",
    "                                                                                      process_duration.seconds/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate)\n",
    "conv_siamese_net.compile(loss=utils.softplus_loss,\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=[utils.auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = conv_siamese_net.to_yaml()\n",
    "with open(os.path.join(path[\"model\"], \"dvbpr.yaml\"), \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the pre-trained models in *models/pre-trained-pre-trained-24early-stopped-epochs-98AUC* directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a user, let's predict the final ranking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly choose a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = random.randrange(user_num)\n",
    "user=312\n",
    "print(\"user idx: %.0f\\nuser name: %s\" % (user, user_train_original[user][0][\"reviewerName\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what she/he likes\n",
    "observed_items_url_cat = utils.get_observed_imUrl_imCat(user_idx=user, \n",
    "                                                        user_train_ratings=user_train_original,  \n",
    "                                                        item_images=items)\n",
    "for idx, url_cat in observed_items_url_cat.items():   \n",
    "    img = utils.image_displayer(url_cat[\"imUrl\"])\n",
    "    print(\"categories: %s\" % (\"; \".join(url_cat[\"imCat\"])))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_url_cat = utils.get_observed_imUrl_imCat(user_idx=user, \n",
    "                                                  user_train_ratings=user_test,  \n",
    "                                                  item_images=items)\n",
    "baseline_id = list(baseline_url_cat.keys())[0]\n",
    "baseline_cat = baseline_url_cat[baseline_id][\"imCat\"]\n",
    "baseline_img = utils.image_translate(items[baseline_id][b'imgs'],\n",
    "                                     image_width,\n",
    "                                     image_height)\n",
    "display(utils.image_displayer(baseline_url_cat[baseline_id][\"imUrl\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what she/he does not reviwed\n",
    "not_observed_item_ids = random.sample(range(len(items)), k=15000)\n",
    "not_observed_item_ids = [item_id for item_id in not_observed_item_ids if item_id not in observed_items_url_cat.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trained layers for that user\n",
    "batch_models = os.listdir(os.path.join(path[\"model\"], \"pre-trained-24early-stopped-epochs-98AUC\"))\n",
    "trained_model = [model for model in batch_models\n",
    "                 if user in user_subsets[int(os.path.splitext(model)[0].split(\"_\")[2])]][0]\n",
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the user matrix \n",
    "user_subset_origin = user_subsets[int(os.path.splitext(trained_model)[0].split(\"_\")[2])][0]\n",
    "user_E = to_categorical(list(range(user - user_subset_origin,\n",
    "                                   user - user_subset_origin + latent_dimensionality)),\n",
    "                        num_classes=latent_dimensionality * len(user_subsets[0])).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the ranking of user's preferences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the DVBPR model\n",
    "dvbpr_ranker = model.ConvSiameseNet(users_dim=len(user_subsets[0]),\n",
    "                                    width=image_width,\n",
    "                                    height=image_height,\n",
    "                                    depth=3,\n",
    "                                    latent_dim=latent_dimensionality,\n",
    "                                    cnn_w_regularizer=l2(lambda_cnn),\n",
    "                                    fc_w_regularizer=l2(lambda_fc),\n",
    "                                    u_w_regularizer=l2(lambda_u)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranfer the trained weights to our predictor\n",
    "dvbpr_ranker.load_weights(os.path.join(path[\"model\"], \"pre-trained-24early-stopped-epochs-98AUC\", \n",
    "                                       os.path.split(trained_model)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the preferences scores for new items\n",
    "user_placeholder = []\n",
    "users_E = []\n",
    "baseline_item_image = []\n",
    "new_item_images = []\n",
    "for item_id in not_observed_item_ids:\n",
    "    user_placeholder.append(1)\n",
    "    users_E.append(user_E)\n",
    "    baseline_item_image.append(baseline_img)\n",
    "    new_item_images.append(utils.image_translate(items[item_id][b'imgs'],\n",
    "                                                      image_width, \n",
    "                                                      image_height)) \n",
    "\n",
    "preference_scores = dict(zip(not_observed_item_ids, \n",
    "                             dvbpr_ranker.predict(\n",
    "                                 [np.array(user_placeholder),\n",
    "                                  np.array(users_E),\n",
    "                                  np.array(baseline_item_image),\n",
    "                                  np.array(new_item_images)])))\n",
    "item_score = pd.DataFrame(preference_scores.items(), columns=[\"item\", \"score\"])\n",
    "item_score[\"score\"] = item_score[\"score\"].map(lambda s: s[0])\n",
    "\n",
    "# and order them on a 0-100 scale\n",
    "item_score.sort_values(\"score\", ascending=False, inplace=True)\n",
    "item_score.set_index(\"item\", inplace=True)\n",
    "item_score[\"score\"] = round((item_score[\"score\"] - min(item_score[\"score\"])) / \\\n",
    "                             (max(item_score[\"score\"]) -  min(item_score[\"score\"])) * 100, 2)\n",
    "item_score[\"categories\"] = item_score.index.map(lambda i: \n",
    "                                                np.unique([cat.decode(\"utf-8\") \n",
    "                                                           for cat in sum(items[i][b'categories'], [])]))\n",
    "item_score[\"close2test\"] = item_score[\"categories\"].map(lambda cat: sum([c in baseline_cat for c in cat]) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's display the predicted ranking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_count = 0\n",
    "for item_idx in item_score.index:\n",
    "    if (suggested_count < 5) & (item_score.loc[item_idx][\"close2test\"]):\n",
    "        img = utils.image_displayer(items[item_idx][b'imUrl'].decode(\"utf-8\"))\n",
    "        print(\"item id %.0f\" % (item_idx))\n",
    "        print(\"score: %.2f\" % (item_score.loc[item_idx, \"score\"]))\n",
    "        display(img)\n",
    "        suggested_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = utils.image_displayer(items[item_idx][b'imUrl'].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
